{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize: ['Guangdong', 'University', 'of', 'Foreign', 'Studies', 'is', 'located', 'in', 'Guangzhou', '.']\n",
      "Part of Speech: [('Guangdong', 'NNP'), ('University', 'NNP'), ('of', 'IN'), ('Foreign', 'NNP'), ('Studies', 'NNPS'), ('is', 'VBZ'), ('located', 'JJ'), ('in', 'IN'), ('Guangzhou', 'NNP'), ('.', '.')]\n",
      "Constituency Parsing: (ROOT\n",
      "  (S\n",
      "    (NP\n",
      "      (NP (NNP Guangdong) (NNP University))\n",
      "      (PP (IN of)\n",
      "        (NP (NNP Foreign) (NNPS Studies))))\n",
      "    (VP (VBZ is)\n",
      "      (ADJP (JJ located)\n",
      "        (PP (IN in)\n",
      "          (NP (NNP Guangzhou)))))\n",
      "    (. .)))\n",
      "Dependency Parsing: [('ROOT', 0, 7), ('compound', 2, 1), ('nsubjpass', 7, 2), ('case', 5, 3), ('compound', 5, 4), ('nmod', 2, 5), ('auxpass', 7, 6), ('case', 9, 8), ('nmod', 7, 9), ('punct', 7, 10)]\n"
     ]
    }
   ],
   "source": [
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "\n",
    "#nlp = st(r'/home/justin/stanford')\n",
    "nlp = StanfordCoreNLP(r'/home/justin/stanford')\n",
    "sentence = 'Guangdong University of Foreign Studies is located in Guangzhou.'\n",
    "print ('Tokenize:', nlp.word_tokenize(sentence))\n",
    "print ('Part of Speech:', nlp.pos_tag(sentence))\n",
    "#print ('Named Entities:', nlp.ner(sentence))\n",
    "print ('Constituency Parsing:', nlp.parse(sentence))\n",
    "print ('Dependency Parsing:', nlp.dependency_parse(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cc', 'cd', 'dt', 'in', 'jj', 'jjr', 'jjs', 'nn', 'nns', 'prp', 'rb', 'to', 'vb', 'vbd', 'vbg', 'vbn', 'vbp', 'vbz', 'wdt', 'wp']\n"
     ]
    }
   ],
   "source": [
    "## from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "sample = [\"I like blankets.\",\"I love sleeping and drinking latte.\",\"As he crossed toward the pharmacy at the corner he involuntarily turned his head because of a burst of light that had ricocheted from his temple, and saw, with that quick smile with which we greet a rainbow or a rose, a blindingly white parallelogram of sky being unloaded from the van—a dresser with mirrors across which, as across a cinema screen, passed a flawlessly clear reflection of boughs sliding and swaying not arboreally, but with a human vacillation, produced by the nature of those who were carrying this sky, these boughs, this gliding façade.\",\"On offering to help the blind man, the man who then stole his car, had not, at that precise moment, had any evil intention, quite the contrary, what he did was nothing more than obey those feelings of generosity and altruism which, as everyone knows, are the two best traits of human nature and to be found in much more hardened criminals than this one, a simple car-thief without any hope of advancing in his profession, exploited by the real owners of this enterprise, for it is they who take advantage of the needs of the poor.\"]\n",
    "syntax = []\n",
    "for sentence in sample:\n",
    "    speech = nlp.pos_tag(sentence)\n",
    "    speech = [x[1] for x in speech]\n",
    "    syntax.append(\" \".join(speech))\n",
    "vect = CountVectorizer()\n",
    "X_train = vect.fit_transform(syntax)\n",
    "print(vect.get_feature_names())\n",
    "y_train=[1,1,2,2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score \n",
    "\n",
    "model = MultinomialNB().fit(X_train[0:3],y_train[0:3])\n",
    "model.predict(X_train[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
